{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = tfds.load(\"cifar10\")\n",
    "train_dataset, test_dataset = datasets[\"train\"], datasets[\"test\"]\n",
    "assert isinstance(train_dataset, tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_builder = tfds.builder('cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = cifar10_builder.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='cifar10',\n",
      "    version=1.0.2,\n",
      "    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',\n",
      "    urls=['https://www.cs.toronto.edu/~kriz/cifar.html'],\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    }),\n",
      "    total_num_examples=60000,\n",
      "    splits={\n",
      "        'test': 10000,\n",
      "        'train': 50000,\n",
      "    },\n",
      "    supervised_keys=('image', 'label'),\n",
      "    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\n",
      "        author = {Alex Krizhevsky},\n",
      "        title = {Learning multiple layers of features from tiny images},\n",
      "        institution = {},\n",
      "        year = {2009}\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'airplane'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.features['label'].int2str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuxCJIGcXIhHk7EIkwr8ARy3ihh5RYWsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[[184 159 149]\n",
      "  [181 157 146]\n",
      "  [182 158 145]\n",
      "  ...\n",
      "  [180 152 138]\n",
      "  [179 151 137]\n",
      "  [178 149 135]]\n",
      "\n",
      " [[181 157 147]\n",
      "  [179 155 144]\n",
      "  [179 155 142]\n",
      "  ...\n",
      "  [177 149 135]\n",
      "  [177 149 135]\n",
      "  [176 148 133]]\n",
      "\n",
      " [[182 158 148]\n",
      "  [179 155 144]\n",
      "  [179 155 143]\n",
      "  ...\n",
      "  [178 150 136]\n",
      "  [177 149 135]\n",
      "  [176 148 134]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[240 227 168]\n",
      "  [235 221 164]\n",
      "  [233 220 162]\n",
      "  ...\n",
      "  [226 202 139]\n",
      "  [225 199 139]\n",
      "  [224 197 138]]\n",
      "\n",
      " [[238 221 164]\n",
      "  [233 217 161]\n",
      "  [233 217 160]\n",
      "  ...\n",
      "  [222 195 133]\n",
      "  [223 193 134]\n",
      "  [221 190 133]]\n",
      "\n",
      " [[233 216 158]\n",
      "  [230 213 157]\n",
      "  [231 214 158]\n",
      "  ...\n",
      "  [222 191 130]\n",
      "  [221 188 130]\n",
      "  [219 185 129]]]\n"
     ]
    }
   ],
   "source": [
    "for example in train_dataset.take(1):  # Only take a single example\n",
    "    plt.imshow(example['image'].numpy())\n",
    "    plt.show()\n",
    "    print(example['label'].numpy())\n",
    "    print(example['image'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataset.batch(50000):\n",
    "    x_train = batch['image']\n",
    "    y_train = batch['label'].numpy().astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[156, 166, 181],\n",
       "        [153, 166, 179],\n",
       "        [153, 168, 181],\n",
       "        ...,\n",
       "        [ 91, 141, 173],\n",
       "        [ 75, 134, 166],\n",
       "        [ 61, 126, 163]],\n",
       "\n",
       "       [[163, 172, 187],\n",
       "        [160, 171, 185],\n",
       "        [157, 171, 184],\n",
       "        ...,\n",
       "        [104, 153, 186],\n",
       "        [ 91, 145, 179],\n",
       "        [ 77, 137, 174]],\n",
       "\n",
       "       [[163, 171, 184],\n",
       "        [168, 178, 189],\n",
       "        [161, 174, 184],\n",
       "        ...,\n",
       "        [117, 162, 193],\n",
       "        [106, 153, 187],\n",
       "        [ 94, 146, 181]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[141, 143, 148],\n",
       "        [132, 140, 148],\n",
       "        [131, 140, 149],\n",
       "        ...,\n",
       "        [171, 172, 176],\n",
       "        [171, 172, 177],\n",
       "        [168, 174, 181]],\n",
       "\n",
       "       [[147, 148, 150],\n",
       "        [133, 139, 147],\n",
       "        [132, 139, 149],\n",
       "        ...,\n",
       "        [170, 171, 175],\n",
       "        [171, 172, 177],\n",
       "        [171, 174, 182]],\n",
       "\n",
       "       [[154, 154, 153],\n",
       "        [132, 137, 143],\n",
       "        [130, 136, 145],\n",
       "        ...,\n",
       "        [166, 167, 172],\n",
       "        [168, 170, 174],\n",
       "        [169, 171, 177]]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[5000].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 9, 3, ..., 9, 3, 7], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCnYhMkHBLkQmKNiFyIT/AyC031QNA9sqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[5000].numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_dataset.batch(10000):\n",
    "    x_test = batch['image']\n",
    "    y_test = batch['label'].numpy().astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 6s 113us/sample - loss: 7.0337 - accuracy: 0.0979\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 5s 98us/sample - loss: 2.3029 - accuracy: 0.0976\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 5s 100us/sample - loss: 2.3028 - accuracy: 0.0991\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 5s 98us/sample - loss: 2.3027 - accuracy: 0.0981\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 5s 104us/sample - loss: 2.3028 - accuracy: 0.1005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26feb367b38>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(32,32,3)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.3028314907073977, 0.0998]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 36s 724us/sample - loss: 1.7524 - accuracy: 0.3953\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 35s 708us/sample - loss: 1.3074 - accuracy: 0.5384\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 35s 702us/sample - loss: 1.1603 - accuracy: 0.5935\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 39s 775us/sample - loss: 1.0501 - accuracy: 0.6371\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 36s 729us/sample - loss: 0.9692 - accuracy: 0.6646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26fec00ee48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1075871005058289, 0.6261]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 15, 15, 64)        4160      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6, 6, 32)          1056      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 110,218\n",
      "Trainable params: 110,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 58s 1ms/sample - loss: 1.6709 - accuracy: 0.4036\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 57s 1ms/sample - loss: 1.3217 - accuracy: 0.5277\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 60s 1ms/sample - loss: 1.1810 - accuracy: 0.5799\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 68s 1ms/sample - loss: 1.0821 - accuracy: 0.6188\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 66s 1ms/sample - loss: 1.0090 - accuracy: 0.6457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26fec95fac8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.238981191444397, 0.582]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 44s 883us/sample - loss: 1.8663 - accuracy: 0.3729\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 46s 915us/sample - loss: 1.3695 - accuracy: 0.5067\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 45s 893us/sample - loss: 1.2280 - accuracy: 0.5650\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 51s 1ms/sample - loss: 1.1153 - accuracy: 0.6066\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 57s 1ms/sample - loss: 1.0338 - accuracy: 0.6367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26fef15cb00>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1423063493728638, 0.5984]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 15, 15, 32)        1056      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6, 6, 64)          4160      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 127,786\n",
      "Trainable params: 127,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 53s 1ms/sample - loss: 1.5937 - accuracy: 0.4272\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 59s 1ms/sample - loss: 1.2047 - accuracy: 0.5754s - loss: 1.2061 - \n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 58s 1ms/sample - loss: 1.0540 - accuracy: 0.6292\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 59s 1ms/sample - loss: 0.9567 - accuracy: 0.6664\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 61s 1ms/sample - loss: 0.8753 - accuracy: 0.6931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26fef95cd68>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9590696385383606, 0.6697]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 15, 15, 32)        1056      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 6, 6, 64)          4160      \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 127,786\n",
      "Trainable params: 127,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 49s 976us/sample - loss: 1.5632 - accuracy: 0.4385\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 53s 1ms/sample - loss: 1.2201 - accuracy: 0.5667\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 49s 980us/sample - loss: 1.0712 - accuracy: 0.6242\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 47s 943us/sample - loss: 0.9691 - accuracy: 0.6588\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 48s 951us/sample - loss: 0.8933 - accuracy: 0.6878\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 42s 843us/sample - loss: 0.8317 - accuracy: 0.7078\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 40s 800us/sample - loss: 0.7829 - accuracy: 0.7240\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 41s 814us/sample - loss: 0.7454 - accuracy: 0.7402\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 43s 853us/sample - loss: 0.7035 - accuracy: 0.7521\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 42s 843us/sample - loss: 0.6558 - accuracy: 0.7703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26ff0497438>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0263936498641968, 0.6822]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (1, 1), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16, 16, 32)        1056      \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 7, 7, 32)          1056      \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 5, 5, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 133,098\n",
      "Trainable params: 133,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 33s 666us/sample - loss: 1.8375 - accuracy: 0.3539\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 35s 709us/sample - loss: 1.4302 - accuracy: 0.4881\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 35s 693us/sample - loss: 1.3007 - accuracy: 0.5371\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 39s 771us/sample - loss: 1.2067 - accuracy: 0.5731\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 39s 772us/sample - loss: 1.1279 - accuracy: 0.6020\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 37s 735us/sample - loss: 1.0656 - accuracy: 0.6235\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 38s 769us/sample - loss: 0.9985 - accuracy: 0.6474\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 39s 782us/sample - loss: 0.9344 - accuracy: 0.6708\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 39s 790us/sample - loss: 0.8801 - accuracy: 0.6914\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 39s 774us/sample - loss: 0.8357 - accuracy: 0.7052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26ff0c16eb8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2165095633506775, 0.5955]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 15, 15, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 13, 13, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 349,034\n",
      "Trainable params: 349,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 121s 2ms/sample - loss: 1.5362 - accuracy: 0.4440\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 122s 2ms/sample - loss: 1.1391 - accuracy: 0.5964\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 120s 2ms/sample - loss: 0.9740 - accuracy: 0.6573\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 118s 2ms/sample - loss: 0.8681 - accuracy: 0.6951\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 119s 2ms/sample - loss: 0.8056 - accuracy: 0.7191\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 119s 2ms/sample - loss: 0.7472 - accuracy: 0.7388\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 122s 2ms/sample - loss: 0.7006 - accuracy: 0.7518\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 120s 2ms/sample - loss: 0.6589 - accuracy: 0.7687\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 122s 2ms/sample - loss: 0.6204 - accuracy: 0.7826\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 124s 2ms/sample - loss: 0.5873 - accuracy: 0.7949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26f8b239630>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9810348806381226, 0.7011]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(.15),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(.15),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 13, 13, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 293,610\n",
      "Trainable params: 293,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 38s 758us/sample - loss: 2.0338 - accuracy: 0.3530\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 43s 855us/sample - loss: 1.4300 - accuracy: 0.4859\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 40s 797us/sample - loss: 1.3054 - accuracy: 0.5387\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 41s 822us/sample - loss: 1.2124 - accuracy: 0.5723\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 40s 807us/sample - loss: 1.1472 - accuracy: 0.5985\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 41s 814us/sample - loss: 1.0872 - accuracy: 0.6187\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 41s 814us/sample - loss: 1.0404 - accuracy: 0.6354\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 41s 829us/sample - loss: 1.0090 - accuracy: 0.6483\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 41s 817us/sample - loss: 0.9851 - accuracy: 0.6556\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 41s 823us/sample - loss: 0.9506 - accuracy: 0.6713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26f8dc519e8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0755102062225341, 0.6315]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,080,042\n",
      "Trainable params: 1,080,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 59s 1ms/sample - loss: 1.7283 - accuracy: 0.4521\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 56s 1ms/sample - loss: 1.1722 - accuracy: 0.5863\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 55s 1ms/sample - loss: 1.0105 - accuracy: 0.6490\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 59s 1ms/sample - loss: 0.8699 - accuracy: 0.6969\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 54s 1ms/sample - loss: 0.7425 - accuracy: 0.7426\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 55s 1ms/sample - loss: 0.6263 - accuracy: 0.7833\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 55s 1ms/sample - loss: 0.5312 - accuracy: 0.8167\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 55s 1ms/sample - loss: 0.4437 - accuracy: 0.8483\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 55s 1ms/sample - loss: 0.3859 - accuracy: 0.8693\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 55s 1ms/sample - loss: 0.3592 - accuracy: 0.8789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26f8c3f69b0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.90528024559021, 0.6188]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_39 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 6, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 814,122\n",
      "Trainable params: 814,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 139s 3ms/sample - loss: 1.5436 - accuracy: 0.4476\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 162s 3ms/sample - loss: 1.0956 - accuracy: 0.6115\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 153s 3ms/sample - loss: 0.9280 - accuracy: 0.6762\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 153s 3ms/sample - loss: 0.8277 - accuracy: 0.7124\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 155s 3ms/sample - loss: 0.7513 - accuracy: 0.7380\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 155s 3ms/sample - loss: 0.6920 - accuracy: 0.7589\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 154s 3ms/sample - loss: 0.6370 - accuracy: 0.7781\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 149s 3ms/sample - loss: 0.5993 - accuracy: 0.7910\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 153s 3ms/sample - loss: 0.5657 - accuracy: 0.8020\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 155s 3ms/sample - loss: 0.5294 - accuracy: 0.8181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26f8f6627f0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.01874582157135, 0.7054]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.applications.VGG19(include_top=False, weights='imagenet', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 1, 1, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 20,158,282\n",
      "Trainable params: 133,898\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 265s 5ms/sample - loss: 2.3419 - accuracy: 0.4806\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 288s 6ms/sample - loss: 1.2163 - accuracy: 0.5819\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 312s 6ms/sample - loss: 1.1370 - accuracy: 0.6085\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 315s 6ms/sample - loss: 1.0908 - accuracy: 0.6241\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 331s 7ms/sample - loss: 1.0485 - accuracy: 0.6381\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 329s 7ms/sample - loss: 1.0010 - accuracy: 0.6555\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 309s 6ms/sample - loss: 0.9576 - accuracy: 0.6681\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 295s 6ms/sample - loss: 0.9112 - accuracy: 0.6860\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 294s 6ms/sample - loss: 0.8746 - accuracy: 0.6972\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 289s 6ms/sample - loss: 0.8432 - accuracy: 0.7070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26f90eee390>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4811181077957154, 0.5851]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lraic\\Anaconda3\\envs\\intel\\lib\\site-packages\\keras_applications\\mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.applications.MobileNet(include_top=False, weights='imagenet', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Model)   (None, 1, 1, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,493,834\n",
      "Trainable params: 264,970\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 99s 2ms/sample - loss: 1.6939 - accuracy: 0.4093\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 103s 2ms/sample - loss: 1.5354 - accuracy: 0.4622\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 135s 3ms/sample - loss: 1.4979 - accuracy: 0.4738\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 161s 3ms/sample - loss: 1.4788 - accuracy: 0.4809\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 116s 2ms/sample - loss: 1.4561 - accuracy: 0.4851\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 121s 2ms/sample - loss: 1.4370 - accuracy: 0.4935\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 122s 2ms/sample - loss: 1.4337 - accuracy: 0.4949\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 121s 2ms/sample - loss: 1.4235 - accuracy: 0.5005\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 121s 2ms/sample - loss: 1.4096 - accuracy: 0.5038\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 120s 2ms/sample - loss: 1.4017 - accuracy: 0.5078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26f94491828>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.3612327419281005, 0.1017]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
